{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "credit-default-prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegV12/GoogleColab/blob/Credit-Default/credit_default_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4Wsax_QRDI5T"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O2A3IOnbDI5b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold, KFold, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error as mse, r2_score as r2\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import svm, linear_model\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import seaborn as sn\n",
        "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from scipy.stats import mannwhitneyu\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from catboost import CatBoostClassifier, Pool, cv\n",
        "import hyperopt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aWfT1SniDI5b"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GYeyN6yDI5c"
      },
      "source": [
        "# Loadind datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x3KBedvcDI5c"
      },
      "source": [
        "TRAIN_DATASET_PATH = '../input/gb-credit-default/train.csv'\n",
        "TEST_DATASET_PATH = '../input/gb-credit-default/test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3KOJj-pwDI5c"
      },
      "source": [
        "train_df = pd.read_csv(TRAIN_DATASET_PATH)\n",
        "test_df = pd.read_csv(TEST_DATASET_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AicPukd0DI5d"
      },
      "source": [
        "train_df.shape[1] - 1 == test_df.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQmKMMkMDI5d"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MIKr2zFbDI5e"
      },
      "source": [
        "train_df['Credit Default'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SgmFvageDI5f"
      },
      "source": [
        "\n",
        "plt.figure(figsize = (16, 8))\n",
        "\n",
        "train_df['Credit Default'].hist(bins=30)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Credit Default')\n",
        "\n",
        "plt.title('Target distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NU2MuJYoDI5f"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Df1uQqgTDI5f"
      },
      "source": [
        "plt.figure(figsize = (25,20))\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "\n",
        "corr_matrix = train_df.corr()\n",
        "corr_matrix = np.round(corr_matrix, 2)\n",
        "corr_matrix[np.abs(corr_matrix) < 0.3] = 0\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap='GnBu')\n",
        "\n",
        "plt.title('Correlation matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtxYRQzsDI5g"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X91J6qHJDI5g"
      },
      "source": [
        "# Fillna and aoutliers with GBR model\n",
        "def imputer_rfr(data, target_col):\n",
        "    data = data.copy()\n",
        "    \n",
        "    features = data.columns\n",
        "    \n",
        "    data = data[features]\n",
        "    \n",
        "    train = data[~data[target_col].isna()]\n",
        "    predict_data = data[data[target_col].isna()]\n",
        "\n",
        "    X = train.drop(columns=target_col)\n",
        "    y = train[target_col]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.2,\n",
        "                                                        shuffle=True,\n",
        "                                                        random_state=32)\n",
        "    \n",
        "    model = GradientBoostingRegressor(n_estimators=110,\n",
        "                                  max_depth=8,\n",
        "                                  random_state=42,\n",
        "                                  loss='huber',\n",
        "                                  learning_rate=0.2)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    pred_train = model.predict(X_train)\n",
        "    pred_test = model.predict(X_test)\n",
        "    \n",
        "    pred = model.predict(predict_data.drop(columns=target_col))\n",
        "    data.loc[data[target_col].isna(), target_col] = list(pred)\n",
        "    return model, data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s7soMc8iDI5g"
      },
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.medians = None\n",
        "        self.years_max_quantille = None\n",
        "        self.credit_max_quantille = None\n",
        "        self.loan_quantille = None\n",
        "\n",
        "    def fit(self, df):\n",
        "        self.medians = df.median()\n",
        "        self.years_max_quantille = np.quantile(df['Years of Credit History'], q=0.95)\n",
        "        self.credit_max_quantille = np.quantile(df['Maximum Open Credit'], q=0.95)\n",
        "        self.loan_quantille = np.quantile(df['Current Loan Amount'], q=0.88)\n",
        "\n",
        "                                               \n",
        "    def transform(self, df):\n",
        "        # 'Home Ownership'\n",
        "        # Have Mortgage = Home Mortgage\n",
        "        df.loc[df['Home Ownership'] == 'Have Mortgage', 'Home Ownership'] = 'Home Mortgage'       \n",
        "        # Replace obj with numeric\n",
        "        df['Ownership'] = df['Home Ownership'].copy()\n",
        "        df = pd.get_dummies(df, columns=['Ownership'])\n",
        "        df.replace({'Home Ownership': {'Own Home': 2, \n",
        "                                       'Home Mortgage': 1, \n",
        "                                       'Rent': 0}\n",
        "                    }, inplace=True)\n",
        "\n",
        "\n",
        "        # 'Years in current job' \n",
        "        # Replace obj with numeric\n",
        "        df.replace({'Years in current job': \n",
        "                                            {'10+ years': 10,\n",
        "                                             '9 years': 9, \n",
        "                                             '8 years': 8,\n",
        "                                             '7 years': 7, \n",
        "                                             '6 years': 6,\n",
        "                                             '5 years': 5,\n",
        "                                             '4 years': 4,\n",
        "                                             '3 years': 3,\n",
        "                                             '2 years': 2,\n",
        "                                             '1 year': 1,\n",
        "                                             '< 1 year': 0,}}, inplace=True)\n",
        "        # Fillna\n",
        "        self.years_in_cur_job_median = df['Years in current job'].median()\n",
        "        df['Years in current job'].fillna(self.years_in_cur_job_median, inplace=True)\n",
        "\n",
        "\n",
        "        # 'Purpose'\n",
        "        df.replace({'Purpose': \n",
        "                                            {'debt consolidation': 0,\n",
        "                                             'other': 1, \n",
        "                                             'home improvements': 1,\n",
        "                                             'take a trip': 1, \n",
        "                                             'buy a car': 1,\n",
        "                                             'small business': 2,\n",
        "                                             'business loan': 2,\n",
        "                                             'wedding': 1,\n",
        "                                             'educational expenses': 1,\n",
        "                                             'buy house': 1,\n",
        "                                             'medical bills': 1,\n",
        "                                             'moving': 1,\n",
        "                                             'major purchase': 1,\n",
        "                                             'vacation':1,\n",
        "                                             'renewable energy':1, }}, \n",
        "                   inplace=True)\n",
        "        # Fillna\n",
        "        df['Purpose'].fillna(1, inplace=True)\n",
        "\n",
        "\n",
        "        # 'Term'\n",
        "        df.replace({'Term': {'Short Term': 0, \n",
        "                             'Long Term': 1}}, inplace=True)\n",
        "        \n",
        "\n",
        "        # 'Months since last delinquent'\n",
        "        # Fillna with number of credit history months\n",
        "        df['Months since last delinquent'].fillna((df['Years of Credit History'] * 12), inplace=True)\n",
        "\n",
        "\n",
        "        # 'Annual Income'\n",
        "        df['Annual Income'].fillna(1, inplace=True)\n",
        "\n",
        "\n",
        "        # 'Credit Score'\n",
        "        df['Credit Score'].fillna(1, inplace=True)\n",
        "        df.loc[df['Credit Score'] > 850, ['Credit Score']] = df['Credit Score'] / 10\n",
        "\n",
        "\n",
        "        # 'Bankruptcies'\n",
        "        df['Bankruptcies'].fillna(0, inplace=True)\n",
        "        \n",
        "        \n",
        "        # 'Years of Credit History'\n",
        "        df['Years of Credit History'].clip(lower=None, upper=self.years_max_quantille, inplace=True)\n",
        "\n",
        "        \n",
        "        # Fillna with GBR model\n",
        "        df.loc[df['Annual Income'] == 1, ['Annual Income']] = np.nan\n",
        "        model, df = imputer_rfr(df, 'Annual Income')\n",
        "\n",
        "        df.loc[df['Credit Score'] == 1, ['Credit Score']] = np.nan\n",
        "        model, df = imputer_rfr(df, 'Credit Score')\n",
        "\n",
        "\n",
        "        df.loc[df['Current Loan Amount'] >= self.loan_quantille, ['Current Loan Amount']] = np.nan\n",
        "        model, df = imputer_rfr(df, 'Current Loan Amount')\n",
        "\n",
        "\n",
        "        df.loc[df['Maximum Open Credit'] > self.credit_max_quantille, ['Maximum Open Credit']] = np.nan\n",
        "        model, df = imputer_rfr(df, 'Maximum Open Credit')\n",
        "\n",
        "        self.months_since_deliq_quantille = np.quantile(df['Months since last delinquent'], q=0.92)\n",
        "        df.loc[df['Months since last delinquent'] > self.months_since_deliq_quantille, ['Months since last delinquent']] = np.nan\n",
        "        model, df = imputer_rfr(df, 'Months since last delinquent')\n",
        "        \n",
        "        \n",
        "        # Fillna just in case\n",
        "        df.fillna(self.medians, inplace=True)\n",
        "\n",
        "        return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BQSqrRcCDI5i"
      },
      "source": [
        "class FeatureGenerator:\n",
        "    def __init__(self):\n",
        "        self.median = None\n",
        "        self.ownership_rating = None\n",
        "        self.job_years_rating = None\n",
        "        self.credit_default_score_mode = None\n",
        "        self.median_loan_by_purpose = None\n",
        "\n",
        "    def fit(self, df):\n",
        "        self.medians = df.median()\n",
        "        self.ownership_rating = df.groupby(['Home Ownership'])['Credit Score'].agg('median').to_dict()\n",
        "        self.job_years_rating = df.groupby(['Years in current job'])['Credit Score'].agg('median').to_dict()\n",
        "        self.credit_default_score_mode = df.groupby(['Credit Default'])['Credit Score'].agg(pd.Series.mode)[1]\n",
        "        self.median_loan_by_purpose = df.groupby(['Purpose'])['Current Loan Amount'].agg('median').to_dict()\n",
        "\n",
        "    def transform(self, df):\n",
        "        # 'Credit to income ratio'\n",
        "        df['Credit to income ratio'] = np.round((df['Annual Income']/12) / df['Monthly Debt'], 3)\n",
        "        df.loc[df['Credit to income ratio'] == np.inf, ['Credit to income ratio']] = df['Credit to income ratio'].median()\n",
        "        \n",
        "        # 'Loan to income ratio'\n",
        "        df['Loan to income ratio'] = np.round((df['Annual Income']/12) / df['Current Loan Amount'], 3)\n",
        "        df.loc[df['Loan to income ratio'] == np.inf, ['Loan to income ratio']] = df['Loan to income ratio'].median()\n",
        "        \n",
        "        # 'Ownership_credit_rating'\n",
        "        df['Ownership_credit_rating'] = df['Home Ownership'].map(self.ownership_rating)\n",
        "\n",
        "        # 'Years in job rating'\n",
        "        df['Years in job rating'] = df['Years in current job'].map(self.job_years_rating)\n",
        "        \n",
        "        # 'Credit Default Score Delta'\n",
        "        df['Credit Default Score Delta'] = abs(df['Credit Score'] - self.credit_default_score_mode)\n",
        "\n",
        "        # 'Loan_by_term'\n",
        "        df['Loan_by_term'] = df['Purpose'].map(self.median_loan_by_purpose)\n",
        "\n",
        "\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvUmzZ54DI5i"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fcIXDNFJDI5j"
      },
      "source": [
        "preprocessor = DataPreprocessor()\n",
        "preprocessor.fit(train_df)\n",
        "train_df = preprocessor.transform(train_df)\n",
        "test_df = preprocessor.transform(test_df)\n",
        "\n",
        "\n",
        "feature_gen = FeatureGenerator()\n",
        "feature_gen.fit(train_df)\n",
        "train_df = feature_gen.transform(train_df)\n",
        "test_df = feature_gen.transform(test_df)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iNrodu71DI5j"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ip5mwrkmDI5j"
      },
      "source": [
        "y = pd.DataFrame(data=train_df['Credit Default'])\n",
        "train_df.drop('Credit Default', axis=1, inplace=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size=0.25, random_state=100, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnvrCPwBDI5k"
      },
      "source": [
        "# Model training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KQYnOWjbDI5k"
      },
      "source": [
        "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
        "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
        "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
        "\n",
        "\n",
        "def evaluate_preds(model, X_train, X_test, y_train, y_test):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Hn-wg3I0DI5k"
      },
      "source": [
        "disbalance = int(y_train.value_counts()[0]) / int(y_train.value_counts()[1])\n",
        "disbalance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Pz58z_RaDI5k"
      },
      "source": [
        "model_catb = CatBoostClassifier(silent=True, random_state=21,\n",
        "                                    #  cat_features=CAT_FEATURE_NAMES,\n",
        "                                    class_weights=[1, disbalance],\n",
        "                                    allow_writing_files=False,\n",
        "                                    learning_rate=0.2,\n",
        "                                    max_depth=3,\n",
        "                                    n_estimators=95,\n",
        "                                    eval_metric='F1',\n",
        "                                    reg_lambda=2.617721518987342,\n",
        "                                    early_stopping_rounds=30,\n",
        "                                    use_best_model=True,\n",
        "                                    custom_metric=['Precision', 'Recall'],\n",
        "                                    subsample=0.8,)\n",
        "                                     \n",
        "model_catb.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
        "\n",
        "evaluate_preds(model_catb, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P4d1at-cDI5k"
      },
      "source": [
        "# cv = StratifiedKFold(n_splits=4, random_state=21, shuffle=True)\n",
        "# parameters = { \n",
        "\n",
        "#               'max_depth':[2, 3], \n",
        "\n",
        "#               'subsample':[0.8,], \n",
        "\n",
        "#               'n_estimators':[65,], \n",
        "#               'learning_rate':[0.1, 0.2, 0.3, 0.4,0.5, 0.6, 0.7, 0.8, 0.9], \n",
        "\n",
        "\n",
        "#               'reg_lambda': [2.617721518987342],\n",
        "#               }\n",
        "\n",
        "# gs = GridSearchCV(model_catb, parameters, \n",
        "#                   scoring='f1', # метрика \n",
        "#                   cv=cv,\n",
        "\n",
        "#                   n_jobs=-1\n",
        "#                   )\n",
        "# gs.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
        "\n",
        "# gs.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P7H2IcwSDI5l"
      },
      "source": [
        "f1_score(y_test, model_catb.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S9Mc0IYADI5l"
      },
      "source": [
        "feature_importances = pd.DataFrame(zip(X_train.columns, \n",
        "                                       model_catb.feature_importances_), \n",
        "                                   columns=['feature_name', 'importance'])\n",
        "\n",
        "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
        "feature_importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tMEuffBDI5l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "39mQtDB7DI5l"
      },
      "source": [
        "SAMPLE_PATH = '../input/gb-credit-default/sample_submission.csv'\n",
        "submit = pd.read_csv(SAMPLE_PATH)\n",
        "submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KPVsRIcdDI5m"
      },
      "source": [
        "predictions = model_catb.predict(test_df)\n",
        "predictions = predictions.astype('int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QilP0jhIDI5m"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3188pUKqDI5m"
      },
      "source": [
        "submit['Credit Default'] = predictions\n",
        "submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "En0Em1jTDI5m"
      },
      "source": [
        "submit.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gvvDhu_BDI5m"
      },
      "source": [
        "submit.to_csv('xgb_submit.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}